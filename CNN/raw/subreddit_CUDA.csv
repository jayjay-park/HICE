,controversiality,parent_id,body,subreddit,id,score,subreddit_id
1176331,0,t3_27kpz9,The Tesla cards exist because of their greatly enhanced double float performance.The Titan is a good example of that difference. Compare the GTXTi to the Titan excepted from wikipedia| |GFLOPS |GFLOPS|||||| |single |double||GTX  Ti| | ||Titan| | |The other thing is numerical accuracy. Noone really cares if that pixel in that first person shooter comes out as grey or a slightly darker grey as long as its essential greyness remains intact. If that one doesnt get carried when doing that earthquake analysis of the skyscraper theyre planning on building heads will roll.One last thing to raise consumer GPUs arent really designed to be going full tack for days on end. Try running multiple hour GPU compute jobs on your home GPU and watch the magic smoke escape.,CUDA,ci1ygy4,5,t5_2s9d9
3534890,0,t1_cpv6ych,No errors just bogus output. The weird thing is that I know it was working at some point but as the program got bigger it started performing a bit oddly so I went back and checked this computation again and it is definitely not working properly.,CUDA,cpv78q9,1,t5_2s9d9
3832056,0,t1_cqrd8ay,Interesting sounds like you have a good understanding of my implementation which is not simple. The Quadro line of GPUs are not great for compute as they are intended for a different purpose. The GTX or Tesla line will give better compute performance for such applications.The advantage of my implementations have is that they have an compute occupancy of  for these example problems. So on the Titan X there theoretically can be  SMs   threads per SM  threads concurrently active at . GHz. The Quadro  has only  SMs a  lower clock speed and runs at PCIE . rather than ..  The compute device memory bandwidth and devicehosthostdevice bandwidth are  worse than the GPUs in the GTX line.My intent by posting that code was to show that GPUs are quite good at simple brute force problems especially because you can launch a very large kernel and let the scheduler handle assigning thread blocks to SMs. In CPU land the approach is much different and I have yet to see a well implemented brute force problem which is faster on a highend CPU vs a highend GPU. In fact those I know who have mapped large problems to both Teslas and the Intel Phi and they have said it is far easier to get the maximal performance out of the GPUs than the CPUs.They way you describe your algorithm implementation it sounds like they may be thread divergence from the conditionals and branching but I can only speculate about that at this time. Does your implementation also have serial dependencies like a DAG problem ? That class of problem is harder to map to parallel architecture though much research work is being done in that area. ,CUDA,cqt35et,2,t5_2s9d9
4474367,0,t1_cs78s0u,Hey super late I know but I really appreciate the review. And youre absolutely right this was to learn CUDA. And thanks for the resources with techniques and tips. As you can tell I am fairly new to CUDA ,CUDA,csunysf,1,t5_2s9d9
4611997,0,t1_ctbx55s,I never had to disable opengl. ,CUDA,ctbx9eg,1,t5_2s9d9
6791913,0,t1_d0lwwr8,gt thats why I was asked to create a programme that while a cuda program is working I get to know how many blocks and so on ... Get it ?I dont understand you will know how many blocks will be used during execution.  If program A uses X blocks and program B uses Y blocks you will know that there is a different amount of blocks for each.  If you want to know about the resources used you can use the Nsight profiler extension for eclipse. ,CUDA,d0m5hk6,1,t5_2s9d9
9166588,0,t1_d8dk6cs,Be sure to blacklist the nouveau driver in Ubuntu. Make sure you dont have any drivers installed through apt either. Basically remove every graphics driver you can and block nouveau from loading. I did not install the driver included with CUDA. I installed the nvidia driver that I downloaded from their driver page the run file. I installed CUDA using the run file and said no when asked to install the graphics driver then installed the one I downloaded separately. Hope that helps. ,CUDA,d8dxka4,1,t5_2s9d9
10694559,0,t1_dcxz4ob,What about if the operation you are performing on data larger than what fits on GPU main memory touches all of the data constantly like a D FFT on a  GB matrix? I can imagine if you do a calculation that just has to churn through GB and only page faults a few times that the performance would be quite close but with an FFT you would be constantly page faulting. I dont have the right hardware to test this but maybe somebody knows.,CUDA,ddj2bsa,1,t5_2s9d9
